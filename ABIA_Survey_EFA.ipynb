{
 "cells": [
  {
   "cell_type": "raw",
   "id": "7d9d89da-b60d-4f77-967b-fd65884d87fa",
   "metadata": {},
   "source": [
    "def missing(df) : \n",
    "    missing_number = df.isnull().sum().sort_values(ascending = False)\n",
    "    missing_percent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending = False)\n",
    "    missing_values = pd.concat([missing_number, missing_percent], axis = 1, keys = ['Missing_number', 'Missing_percent'])\n",
    "    return missing_values \n",
    "\n",
    "def categorize(df) :\n",
    "    Quantitive_features = df.select_dtypes([np.number]).columns.tolist()\n",
    "    Categorical_features = df.select_dtypes(exclude = [np.number]).columns.tolist()\n",
    "    Discrete_features = [col for col in Quantitive_features if len(df[col].unique()) < 200]\n",
    "    Continuous_features = [col for col in Quantitive_features if col not in Discrete_features]\n",
    "    print(\"Quantitive feautres : {} \\nDiscrete features : {} \\nContinous features : {} \\nCategorical features : {}\\n\"\n",
    "     .format(Quantitive_features, Discrete_features, Continuous_features, Categorical_features))\n",
    "    print(\"Number of quantitive feautres : {} \\nNumber of discrete features : {} \\nNumber of continous features : {} \\nNumber of categorical features : {}\"\n",
    "     .format(len(Quantitive_features), len(Discrete_features), len(Continuous_features), len(Categorical_features)))\n",
    "    return Quantitive_features, Categorical_features, Discrete_features, Continuous_features\n",
    "    \n",
    "def unique(df) : \n",
    "    tb1 = pd.DataFrame({'Columns' : df.columns, 'Number_of_Unique' : df.nunique().values.tolist(),\n",
    "                       'Sample1' : df.sample(1).values.tolist()[0], 'Sample2' : df.sample(1).values.tolist()[0], \n",
    "                       'Sample3' : df.sample(1).values.tolist()[0],\n",
    "                       'Sample4' : df.sample(1).values.tolist()[0], 'Sample5' : df.sample(1).values.tolist()[0]})\n",
    "    return tb1\n",
    "    \n",
    "def data_glimpse(df) :  \n",
    "      # Dataset preview \n",
    "    print(\"1. Dataset Preview \\n\")\n",
    "    display(df.head())\n",
    "    print(\"-------------------------------------------------------------------------------\\n\")\n",
    "    \n",
    "    # Columns imformation\n",
    "    print(\"2. Column Imformation \\n\")\n",
    "    print(\"Dataset have {} rows and {} columns\".format(df.shape[0], df.shape[1]))\n",
    "    print(\"\\n\") \n",
    "    print(\"Dataset Column name : {}\".format(df.columns.values))\n",
    "    print(\"\\n\")\n",
    "    categorize(df)\n",
    "    print(\"-------------------------------------------------------------------------------\\n\")\n",
    "    \n",
    "    # Basic imformation table \n",
    "    print(\"3. Missing data table : \\n\")\n",
    "    display(missing(df))\n",
    "    print(\"-------------------------------------------------------------------------------\\n\")\n",
    "    \n",
    "    print(\"4. Number of unique value by column : \\n\")\n",
    "    display(unique(df))\n",
    "    print(\"-------------------------------------------------------------------------------\\n\")\n",
    "    \n",
    "    print(\"5. Describe table : \\n\")\n",
    "    display(df.describe())\n",
    "    print(\"-------------------------------------------------------------------------------\\n\")\n",
    "    \n",
    "    print(df.info())\n",
    "    print(\"-------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "35eaf3e1-c848-49f7-b247-2e7a84f9457a",
   "metadata": {},
   "source": [
    "# Data Analysis\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "    \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "    \n",
    "# Data View\n",
    "pd.options.display.max_columns = 200\n",
    "\n",
    "# Import Basic Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "    \n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bc57c007-38dc-4023-886b-1e00d639f99a",
   "metadata": {},
   "source": [
    "df_raw= pd.read_csv(\"C:\\\\1Users\\\\jason\\\\OneDrive\\\\Desktop\\\\NCU\\\\8525_Multivariate Analysis\\\\Week 8\\\\Airport_Quarterly_Passenger_Survey.csv\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "153b6ea4-3d88-48da-a8f5-f5b2dafe075b",
   "metadata": {},
   "source": [
    "data_glimpse(df_raw)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "62e468b2-ce23-43b2-8657-71fbc3604e6b",
   "metadata": {},
   "source": [
    "#Check Data Type\n",
    "df_raw.dtypes"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fcbb2b6d-3d5d-41bf-b43b-a5ac4ec2eaf1",
   "metadata": {},
   "source": [
    "df_raw.head() #preview first five rows"
   ]
  },
  {
   "cell_type": "raw",
   "id": "df8ace7e-3640-49e3-8d5d-a6841b8cdba8",
   "metadata": {},
   "source": [
    "df_raw.describe() #get summary statistics about the dataset"
   ]
  },
  {
   "cell_type": "raw",
   "id": "58c65f6d-4833-4628-9a85-feda68207b78",
   "metadata": {},
   "source": [
    "df_raw.info() #get additional detail from data i.e., count of non-null"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1ce3af6e-f586-48e7-ab29-9a8d600c4a76",
   "metadata": {},
   "source": [
    "#Removing any row with NA's in the response variable\n",
    "\n",
    "df_dropna = df_raw.dropna(subset=['Overall satisfaction'])\n",
    "df_dropna.describe()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "702ca849-3245-4768-86c0-464127b34733",
   "metadata": {},
   "source": [
    "# Impute median value to NAs\n",
    "df_impute = df_dropna.fillna(df_dropna.median())\n",
    "df_impute.describe()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "65321dbf-23ad-490b-8f1e-9d61028caaf0",
   "metadata": {},
   "source": [
    "# Glimpse new data after imputation\n",
    "\n",
    "data_glimpse(df_impute)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8cd63af7-61d8-4ec9-8206-85c02de59d71",
   "metadata": {},
   "source": [
    "# Check the average of values for the explanatary variables. Grouped by the response variable.\n",
    "df_impute.groupby('Overall satisfaction').mean()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5411ee1b-a939-41d6-830b-cb38d0b00ddd",
   "metadata": {},
   "source": [
    "#Removing any row with 0's in the response variable\n",
    "\n",
    "df_clean = df_impute[(df_impute[['Overall satisfaction']] != 0).all(axis=1)]\n",
    "df_clean.describe()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a8273af5-25d3-45d0-8f79-20705f35b51f",
   "metadata": {},
   "source": [
    "#Correlation matrix\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "c= df_clean.corr()\n",
    "sns.heatmap(c)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cdfe2e7f-b4e9-45c6-9d1b-642520def44f",
   "metadata": {},
   "source": [
    "# Create Correlation Matrix\n",
    "corrmatrix = df_clean.corr()\n",
    "print(corrmatrix)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "16ba288b-1a42-4e8d-b713-a7a0ea2e6884",
   "metadata": {},
   "source": [
    "# Bar chart of frequency in the response variable\n",
    "# series of counts\n",
    "OScount = df_clean['Overall satisfaction'].value_counts()\n",
    "# get bar chart\n",
    "OScount.plot(kind='bar')\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bf90afed-a426-4692-845d-01339bb199bc",
   "metadata": {},
   "source": [
    "list(df_clean.columns[3:36].values.tolist())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a76073c9-d381-40f0-aeff-88e576d7ef98",
   "metadata": {},
   "source": [
    "#Subset of the data\n",
    "!pip install factor_analyzer  \n",
    "from factor_analyzer import FactorAnalyzer\n",
    "\n",
    "x =df_clean[df_clean.columns[3:36]]\n",
    "\n",
    "fa = FactorAnalyzer()\n",
    "fa.fit(x, 10)\n",
    "\n",
    "#Get Eigen values and plot\n",
    "ev, v = fa.get_eigenvalues()\n",
    "ev\n",
    "plt.plot(range(1,x.shape[1]+1),ev)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bf68bd0d-3844-4c81-9a58-70b947f4c1e0",
   "metadata": {},
   "source": [
    "#Conduct Shapiro-Wilks normality test \n",
    "from scipy import stats\n",
    "\n",
    "for i in df_clean.columns[3:36]:\n",
    "    print([i])\n",
    "    a,b = stats.shapiro(df_clean[[i]])\n",
    "    print(\"Statistics\", a, \"p-value\", b)\n",
    "    if b < a:\n",
    "        print(\"The null hypothesis can be rejected\")\n",
    "    else:\n",
    "        print(\"the null hypothesis cannot be rejected\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "df9d936d-3248-4459-a312-40062b3cf535",
   "metadata": {},
   "source": [
    "!pip install scipy\n",
    "from scipy.stats import studentized_range\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "257a9db2-363e-437b-b00f-33f685ba5faa",
   "metadata": {},
   "source": [
    "!pip install pingouin\n",
    "from pingouin import multivariate_normality"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8a11678b-b698-4c0b-9ec8-c08a3259ac7e",
   "metadata": {},
   "source": [
    "#Perform Mardia multivariate normality test\n",
    "multivariate_normality(x,alpha =.05)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c544b7e9-c09b-4d4b-b82a-b66f4a3a3d3e",
   "metadata": {},
   "source": [
    "#Kaiser-Meyer-Olkin (KMO) Measure of Samnpling Adequacy (MSA)\n",
    "\n",
    "from factor_analyzer.factor_analyzer import calculate_kmo\n",
    "\n",
    "kmo_all,kmo_model=calculate_kmo(x)\n",
    "print(kmo_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0f7ede3e-6e17-46ca-b683-2383c29ba739",
   "metadata": {},
   "source": [
    "#Bartlet's test of sphericity\n",
    "from factor_analyzer.factor_analyzer import calculate_bartlett_sphericity\n",
    "\n",
    "chi_square_value,p_value=calculate_bartlett_sphericity(x)\n",
    "print(chi_square_value, p_value)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d7d2596a-09ff-48e4-a28f-5438ce15fbeb",
   "metadata": {},
   "source": [
    "#get load from factors\n",
    "fa = FactorAnalyzer(6, rotation='varimax', method='principal')\n",
    "fa.fit(x)\n",
    "loads = fa.loadings_\n",
    "print(loads)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5e4853c3-f0bf-4a3b-9b5e-cdf1b12e6661",
   "metadata": {},
   "source": [
    "#Get factor correlation\n",
    "\n",
    "fa_corr = fa.corr_\n",
    "print(fa_corr)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1366ae2d-4453-4505-9444-b2dd7a394d5b",
   "metadata": {},
   "source": [
    "#Get rotation matrix\n",
    "\n",
    "fa_rotation = fa.rotation_matrix_\n",
    "print(fa_rotation)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ade9b662-d60e-4ee1-ae1f-ec69463787f6",
   "metadata": {},
   "source": [
    "#Get factor communalities\n",
    "\n",
    "fa_commu = fa.get_communalities()\n",
    "print(fa_commu)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7c5e2131-781d-4e7f-aa46-a2198232deca",
   "metadata": {},
   "source": [
    "#Get eigenvalues\n",
    "fa_ev = fa.get_eigenvalues()\n",
    "print(fa_ev)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "961d8897-c792-4c1d-aa02-952e3a4abec5",
   "metadata": {},
   "source": [
    "#Get uniqueness\n",
    "fa_uniq = fa.get_uniquenesses()\n",
    "print(fa_uniq)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1ae58538-abf1-42ad-913b-8fa30950e05f",
   "metadata": {},
   "source": [
    "#Create Factors\n",
    "\n",
    "factor1 = df_clean[['Wait time at passport inspection', 'Courtesy of inspection staff', 'Courtesy of security staff', 'Thoroughness of security inspection', 'Wait time of security inspection', 'Feeling of safety and security' ]]\n",
    "factor2 = df_clean[['Ease of making connections', 'Courtesy of airport staff', 'Availability of banks/ATM/money changing', 'Shopping facilities', 'Shopping facilities (value for money)', 'Internet access' ]]\n",
    "factor3 = df_clean[['Ease of finding your way through the airport', 'Flight information screens','Walking distance inside terminal' ]]\n",
    "factor4 = df_clean[['Ground transportation to/from airport', 'Parking facilities', 'Parking facilities (value for money)', 'Availability of baggage carts']]\n",
    "factor5 = df_clean[['Efficiency of check-in staff', 'Check-in wait time', 'Courtesy of of check-in staff']]\n",
    "factor6 = df_clean[['Restaurants','Restaurants (value for money)']]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "70b46192-b909-478d-adb3-29e1edfde717",
   "metadata": {},
   "source": [
    "#Get cronback alpha\n",
    "\n",
    "import pingouin as pg\n",
    "\n",
    "f1_alpha = pg.cronbach_alpha(factor1)\n",
    "f2_alpha = pg.cronbach_alpha(factor2)\n",
    "f3_alpha = pg.cronbach_alpha(factor3)\n",
    "f4_alpha = pg.cronbach_alpha(factor4)\n",
    "f5_alpha = pg.cronbach_alpha(factor5)\n",
    "f6_alpha = pg.cronbach_alpha(factor6)\n",
    "\n",
    "print(f1_alpha, f2_alpha, f3_alpha, f4_alpha, f5_alpha, f6_alpha, )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

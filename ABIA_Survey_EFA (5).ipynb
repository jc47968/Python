{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517601c2-bcf5-4d0e-bdef-7a0b8fc16958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing(df) : \n",
    "    missing_number = df.isnull().sum().sort_values(ascending = False)\n",
    "    missing_percent = (df.isnull().sum()/df.isnull().count()).sort_values(ascending = False)\n",
    "    missing_values = pd.concat([missing_number, missing_percent], axis = 1, keys = ['Missing_number', 'Missing_percent'])\n",
    "    return missing_values \n",
    "\n",
    "def categorize(df) :\n",
    "    Quantitive_features = df.select_dtypes([np.number]).columns.tolist()\n",
    "    Categorical_features = df.select_dtypes(exclude = [np.number]).columns.tolist()\n",
    "    Discrete_features = [col for col in Quantitive_features if len(df[col].unique()) < 200]\n",
    "    Continuous_features = [col for col in Quantitive_features if col not in Discrete_features]\n",
    "    print(\"Quantitive feautres : {} \\nDiscrete features : {} \\nContinous features : {} \\nCategorical features : {}\\n\"\n",
    "     .format(Quantitive_features, Discrete_features, Continuous_features, Categorical_features))\n",
    "    print(\"Number of quantitive feautres : {} \\nNumber of discrete features : {} \\nNumber of continous features : {} \\nNumber of categorical features : {}\"\n",
    "     .format(len(Quantitive_features), len(Discrete_features), len(Continuous_features), len(Categorical_features)))\n",
    "    return Quantitive_features, Categorical_features, Discrete_features, Continuous_features\n",
    "    \n",
    "def unique(df) : \n",
    "    tb1 = pd.DataFrame({'Columns' : df.columns, 'Number_of_Unique' : df.nunique().values.tolist(),\n",
    "                       'Sample1' : df.sample(1).values.tolist()[0], 'Sample2' : df.sample(1).values.tolist()[0], \n",
    "                       'Sample3' : df.sample(1).values.tolist()[0],\n",
    "                       'Sample4' : df.sample(1).values.tolist()[0], 'Sample5' : df.sample(1).values.tolist()[0]})\n",
    "    return tb1\n",
    "    \n",
    "def data_glimpse(df) :  \n",
    "      # Dataset preview \n",
    "    print(\"1. Dataset Preview \\n\")\n",
    "    display(df.head())\n",
    "    print(\"-------------------------------------------------------------------------------\\n\")\n",
    "    \n",
    "    # Columns imformation\n",
    "    print(\"2. Column Imformation \\n\")\n",
    "    print(\"Dataset have {} rows and {} columns\".format(df.shape[0], df.shape[1]))\n",
    "    print(\"\\n\") \n",
    "    print(\"Dataset Column name : {}\".format(df.columns.values))\n",
    "    print(\"\\n\")\n",
    "    categorize(df)\n",
    "    print(\"-------------------------------------------------------------------------------\\n\")\n",
    "    \n",
    "    # Basic imformation table \n",
    "    print(\"3. Missing data table : \\n\")\n",
    "    display(missing(df))\n",
    "    print(\"-------------------------------------------------------------------------------\\n\")\n",
    "    \n",
    "    print(\"4. Number of unique value by column : \\n\")\n",
    "    display(unique(df))\n",
    "    print(\"-------------------------------------------------------------------------------\\n\")\n",
    "    \n",
    "    print(\"5. Describe table : \\n\")\n",
    "    display(df.describe())\n",
    "    print(\"-------------------------------------------------------------------------------\\n\")\n",
    "    \n",
    "    print(df.info())\n",
    "    print(\"-------------------------------------------------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd90802-b29f-450b-850d-daae5425df33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Analysis\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "    \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "    \n",
    "# Data View\n",
    "pd.options.display.max_columns = 200\n",
    "\n",
    "# Import Basic Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde13f88-025d-4745-b8f8-8215397314ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw= pd.read_csv(\"C:\\\\Users\\\\jason\\\\OneDrive\\\\Desktop\\\\NCU\\\\8525_Multivariate Analysis\\\\Week 8\\\\Airport_Quarterly_Passenger_Survey.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd90454-93cf-4b78-afc1-fc85941596f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_glimpse(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a7d143-bdb0-44c0-9dae-79b0c8c66fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check Data Type\n",
    "df_raw.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ec4d8e-2a7e-443f-9aed-f795474565a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.head() #preview first five rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a81bcc6-bbbf-4c59-a033-9e11b89c7b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.describe() #get summary statistics about the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48506d7-1f93-46ce-877d-a36eea5d29a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw.info() #get additional detail from data i.e., count of non-null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f3f6ac-8cf6-46fb-af28-c4faeed1a88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing any row with NA's in the response variable\n",
    "\n",
    "df_dropna = df_raw.dropna(subset=['Overall satisfaction'])\n",
    "df_dropna.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e6415b-49bb-4bb3-a231-cd12134ed365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute median value to NAs\n",
    "df_impute = df_dropna.fillna(df_dropna.median())\n",
    "df_impute.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5743aaa7-f237-4d8b-9c99-1f11edeb8e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Glimpse new data after imputation\n",
    "\n",
    "data_glimpse(df_impute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719627bb-02bc-44d7-8a84-2bd6e18aa6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the average of values for the explanatary variables. Grouped by the response variable.\n",
    "df_impute.groupby('Overall satisfaction').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bf42b9-dd0b-4d32-b367-92cfb42d869b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing any row with 0's in the response variable\n",
    "\n",
    "df_clean = df_impute[(df_impute[['Overall satisfaction']] != 0).all(axis=1)]\n",
    "df_clean.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a1540c-b0cd-470c-823c-376e6faa282b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation matrix\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "c= df_clean.corr()\n",
    "sns.heatmap(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22bf91d-c06b-4bac-80c1-fbb0c6d805ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Correlation Matrix\n",
    "corrmatrix = df_clean.corr()\n",
    "print(corrmatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4aa6695-9c13-4010-953f-f180aa3d7d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart of frequency in the response variable\n",
    "# series of counts\n",
    "OScount = df_clean['Overall satisfaction'].value_counts()\n",
    "# get bar chart\n",
    "OScount.plot(kind='bar')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8425b44f-6809-4e3c-9ce8-de6dd423df85",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_clean.columns[3:36].values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf8f7cb-7f9e-48c9-b585-ba4b3b1e6ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subset of the data\n",
    "!pip install factor_analyzer  \n",
    "from factor_analyzer import FactorAnalyzer\n",
    "\n",
    "x =df_clean[df_clean.columns[3:36]]\n",
    "\n",
    "fa = FactorAnalyzer()\n",
    "fa.fit(x, 10)\n",
    "\n",
    "#Get Eigen values and plot\n",
    "ev, v = fa.get_eigenvalues()\n",
    "ev\n",
    "plt.plot(range(1,x.shape[1]+1),ev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d188bf0-54a4-4723-b5d5-bb9c421a18cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conduct Shapiro-Wilks normality test \n",
    "from scipy import stats\n",
    "\n",
    "for i in df_clean.columns[3:36]:\n",
    "    print([i])\n",
    "    a,b = stats.shapiro(df_clean[[i]])\n",
    "    print(\"Statistics\", a, \"p-value\", b)\n",
    "    if b < a:\n",
    "        print(\"The null hypothesis can be rejected\")\n",
    "    else:\n",
    "        print(\"the null hypothesis cannot be rejected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fb885e-f175-4585-86cf-036693022b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scipy\n",
    "from scipy.stats import studentized_range\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df04543-c172-4ceb-9afe-2ad218210bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pingouin\n",
    "from pingouin import multivariate_normality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90913957-03ea-47ee-aa3d-0324ee31d2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform Mardia multivariate normality test\n",
    "multivariate_normality(x,alpha =.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e0271f-06e4-4327-b830-fa1fe8809685",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kaiser-Meyer-Olkin (KMO) Measure of Samnpling Adequacy (MSA)\n",
    "\n",
    "from factor_analyzer.factor_analyzer import calculate_kmo\n",
    "\n",
    "kmo_all,kmo_model=calculate_kmo(x)\n",
    "print(kmo_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca24598-1161-4116-b9cd-b338c191e5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bartlet's test of sphericity\n",
    "from factor_analyzer.factor_analyzer import calculate_bartlett_sphericity\n",
    "\n",
    "chi_square_value,p_value=calculate_bartlett_sphericity(x)\n",
    "print(chi_square_value, p_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375a6896-48c8-46c5-83d2-011e1e7b78e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get load from factors\n",
    "fa = FactorAnalyzer(6, rotation='varimax', method='principal')\n",
    "fa.fit(x)\n",
    "loads = fa.loadings_\n",
    "print(loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4376ed50-369e-4af8-8a70-633b28fa3077",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get factor correlation\n",
    "\n",
    "fa_corr = fa.corr_\n",
    "print(fa_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dcad6b-5ccc-46d7-9744-27d01a2cd44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get rotation matrix\n",
    "\n",
    "fa_rotation = fa.rotation_matrix_\n",
    "print(fa_rotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d9d119-ee48-4c54-bc22-6d789387bc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get factor communalities\n",
    "\n",
    "fa_commu = fa.get_communalities()\n",
    "print(fa_commu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5a06a5-ca56-4422-8fd8-b1bcfbff78e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get eigenvalues\n",
    "fa_ev = fa.get_eigenvalues()\n",
    "print(fa_ev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60be43af-e358-43e7-81c8-89fb03cf78d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get uniqueness\n",
    "fa_uniq = fa.get_uniquenesses()\n",
    "print(fa_uniq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a890c3ea-eaf1-4646-a01e-252be8bb91e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Factors\n",
    "\n",
    "factor1 = df_clean[['Wait time at passport inspection', 'Courtesy of inspection staff', 'Courtesy of security staff', 'Thoroughness of security inspection', 'Wait time of security inspection', 'Feeling of safety and security' ]]\n",
    "factor2 = df_clean[['Ease of making connections', 'Courtesy of airport staff', 'Availability of banks/ATM/money changing', 'Shopping facilities', 'Shopping facilities (value for money)', 'Internet access' ]]\n",
    "factor3 = df_clean[['Ease of finding your way through the airport', 'Flight information screens','Walking distance inside terminal' ]]\n",
    "factor4 = df_clean[['Ground transportation to/from airport', 'Parking facilities', 'Parking facilities (value for money)', 'Availability of baggage carts']]\n",
    "factor5 = df_clean[['Efficiency of check-in staff', 'Check-in wait time', 'Courtesy of of check-in staff']]\n",
    "factor6 = df_clean[['Restaurants','Restaurants (value for money)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d3d408-c18e-4bd9-a26f-7ac3154dbdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get cronback alpha\n",
    "\n",
    "import pingouin as pg\n",
    "\n",
    "f1_alpha = pg.cronbach_alpha(factor1)\n",
    "f2_alpha = pg.cronbach_alpha(factor2)\n",
    "f3_alpha = pg.cronbach_alpha(factor3)\n",
    "f4_alpha = pg.cronbach_alpha(factor4)\n",
    "f5_alpha = pg.cronbach_alpha(factor5)\n",
    "f6_alpha = pg.cronbach_alpha(factor6)\n",
    "\n",
    "print(f1_alpha, f2_alpha, f3_alpha, f4_alpha, f5_alpha, f6_alpha, )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
